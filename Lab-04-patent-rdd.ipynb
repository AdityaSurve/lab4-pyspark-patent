{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSCI 4253 / 5253 - Lab #4 - Patent Problem with Spark RDD - SOLUTION\n",
        "<div>\n",
        " <h2> CSCI 4283 / 5253 \n",
        "  <IMG SRC=\"https://www.colorado.edu/cs/profiles/express/themes/cuspirit/logo.png\" WIDTH=50 ALIGN=\"right\"/> </h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This [Spark cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PySpark_SQL_Cheat_Sheet_Python.pdf) is useful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "import numpy as np\n",
        "import operator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "conf=SparkConf().setAppName(\"Lab4-rdd\").setMaster(\"local[*]\")\n",
        "sc = SparkContext(conf=conf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using PySpark and RDD's on the https://coding.csel.io machines is slow -- most of the code is executed in Python and this is much less efficient than the java-based code using the PySpark dataframes. Be patient and trying using `.cache()` to cache the output of joins. You may want to start with a reduced set of data before running the full task. You can use the `sample()` method to extract just a sample of the data or use "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These two RDD's are called \"rawCitations\" and \"rawPatents\" because you probably want to process them futher (e.g. convert them to integer types, etc). \n",
        "\n",
        "The `textFile` function returns data in strings. This should work fine for this lab.\n",
        "\n",
        "Other methods you use might return data in type `Byte`. If you haven't used Python `Byte` types before, google it. You can convert a value of `x` type byte into e.g. a UTF8 string using `x.decode('uft-8')`. Alternatively, you can use the `open` method of the gzip library to read in all the lines as UTF-8 strings like this:\n",
        "```\n",
        "import gzip\n",
        "with gzip.open('cite75_99.txt.gz', 'rt',encoding='utf-8') as f:\n",
        "    rddCitations = sc.parallelize( f.readlines() )\n",
        "```\n",
        "This is less efficient than using `textFile` because `textFile` would use the underlying HDFS or other file system to read the file across all the worker nodes while the using `gzip.open()...readlines()` will read all the data in the frontend and then distribute it to all the worker nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "rddCitations = sc.textFile(\"cite75_99.txt.gz\")\n",
        "rddPatents = sc.textFile(\"apat63_99.txt.gz\")\n",
        "\n",
        "# SAMPLE!!! COMMENT IT BEFORE SUBMISSION\n",
        "rddCitations = rddCitations.sample(False, 0.05)\n",
        "rddPatents = rddPatents.sample(False, 0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data looks like the following."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"CITING\",\"CITED\"',\n",
              " '3858241,956203',\n",
              " '3858241,1324234',\n",
              " '3858241,3398406',\n",
              " '3858241,3557384']"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rddCitations.take(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"PATENT\",\"GYEAR\",\"GDATE\",\"APPYEAR\",\"COUNTRY\",\"POSTATE\",\"ASSIGNEE\",\"ASSCODE\",\"CLAIMS\",\"NCLASS\",\"CAT\",\"SUBCAT\",\"CMADE\",\"CRECEIVE\",\"RATIOCIT\",\"GENERAL\",\"ORIGINAL\",\"FWDAPLAG\",\"BCKGTLAG\",\"SELFCTUB\",\"SELFCTLB\",\"SECDUPBD\",\"SECDLWBD\"',\n",
              " '3070801,1963,1096,,\"BE\",\"\",,1,,269,6,69,,1,,0,,,,,,,',\n",
              " '3070802,1963,1096,,\"US\",\"TX\",,1,,2,6,63,,0,,,,,,,,,',\n",
              " '3070803,1963,1096,,\"US\",\"IL\",,1,,2,6,63,,9,,0.3704,,,,,,,',\n",
              " '3070804,1963,1096,,\"US\",\"OH\",,1,,2,6,63,,3,,0.6667,,,,,,,']"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rddPatents.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In other words, they are a single string with multiple CSV's. You will need to convert these to (K,V) pairs, probably convert the keys to `int` and so on. You'll need to `filter` out the header string as well since there's no easy way to extract all the lines except the first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parsing and algorithm\n",
        "\n",
        "- **Citations**: Skip header line; split by comma â†’ (citing, cited) as ints.\n",
        "- **Patents**: Skip header; parse CSV to get PATENT (col 0), COUNTRY (4), POSTATE (5). Build (patent_id, state) for US with state, and (patent_id, full_line) for lookup.\n",
        "- **Join**: Join citations with patent states for citing and cited; keep only same state; count per citing patent.\n",
        "- **Top 10**: Join counts with full patent lines, sort by count desc, take 10 and append \",{count}\" to each line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import io\n",
        "\n",
        "def is_header(line):\n",
        "    return '\"CITING\"' in line or '\"PATENT\"' in line\n",
        "\n",
        "def parse_citation(line):\n",
        "    parts = line.split(\",\")\n",
        "    return (int(parts[0]), int(parts[1]))\n",
        "\n",
        "def parse_patent(line):\n",
        "    row = next(csv.reader(io.StringIO(line)))\n",
        "    patent_id = int(row[0])\n",
        "    country = row[4] if len(row) > 4 else \"\"\n",
        "    state = (row[5].strip() if len(row) > 5 and row[5] else \"\") or None\n",
        "    if country == \"US\" and state:\n",
        "        return (patent_id, (\"state\", state, line))\n",
        "    return (patent_id, (\"line\", None, line))\n",
        "\n",
        "citations_rdd = rddCitations.filter(lambda x: not is_header(x)).map(parse_citation)\n",
        "patents_parsed = rddPatents.filter(lambda x: not is_header(x)).map(parse_patent)\n",
        "\n",
        "patent_states = patents_parsed.filter(lambda x: x[1][0] == \"state\").map(lambda x: (x[0], x[1][1]))\n",
        "patent_lines = patents_parsed.map(lambda x: (x[0], x[1][2]))\n",
        "\n",
        "patent_states.cache()\n",
        "patent_lines.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with_citing = citations_rdd.map(lambda x: (x[0], (x[1],))).join(patent_states)\n",
        "with_citing = with_citing.map(lambda x: (x[1][0][0], (x[0], x[1][1])))\n",
        "with_both = with_citing.join(patent_states)\n",
        "\n",
        "same_state = (with_both\n",
        "    .filter(lambda x: x[1][0][1] == x[1][1])\n",
        "    .map(lambda x: (x[1][0][0], 1))\n",
        "    .reduceByKey(operator.add)\n",
        ")\n",
        "same_state.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top10_counts = same_state.takeOrdered(10, key=lambda x: -x[1])\n",
        "\n",
        "patent_lines_dict = patent_lines.collectAsMap()\n",
        "for patent_id, count_val in top10_counts:\n",
        "    line = patent_lines_dict.get(patent_id, \"\")\n",
        "    if line:\n",
        "        print(line + \",\" + str(count_val))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
